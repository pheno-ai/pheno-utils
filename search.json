[
  {
    "objectID": "ecg_analysis.html",
    "href": "ecg_analysis.html",
    "title": "ECG analysis",
    "section": "",
    "text": "source\n\nvis_ecg\n\n vis_ecg (values_df:pandas.core.frame.DataFrame)\n\nVisualize ECG data for 12 leads.\nArgs: values_df (pd.DataFrame): A DataFrame containing ECG data with 12 columns, one for each lead.\nReturns: None: Displays a 3x4 grid of ECG plots for the 12 leads.\n\nsource\n\n\nget_hrv_df\n\n get_hrv_df (ECG_df:pandas.core.frame.DataFrame, sr:int=1000)\n\nCompute the Heart Rate Variability (HRV) metrics for each ECG lead in the input DataFrame.\nArgs: ECG_df (pd.DataFrame): A DataFrame containing ECG data with one column for each lead. sr (int, optional): The sampling rate of the ECG data. Defaults to 1000.\nReturns: pd.DataFrame: A DataFrame containing HRV metrics for each ECG lead."
  },
  {
    "objectID": "config.html",
    "href": "config.html",
    "title": "Config",
    "section": "",
    "text": "source\n\ngenerate_synthetic_data\n\n generate_synthetic_data (n:int=1000)\n\nGenerates a sample DataFrame containing age, gender, and value data.\nArgs: n: The number of rows in the generated DataFrame.\nReturns: A pandas DataFrame with columns ‘age’, ‘gender’, and ‘val’.\n\nsource\n\n\ngenerate_synthetic_data_like\n\n generate_synthetic_data_like (df:pandas.core.frame.DataFrame, n:int=1000,\n                               random_seed:int=42)\n\nGenerate a sample DataFrame containing the same columns as df, but with random data.\nArgs:\ndf: The DataFrame whose columns should be used.\nn: The number of rows in the generated DataFrame.\nReturns: A pandas DataFrame with the same columns as df.\n\ndata = generate_synthetic_data()\ndata.head()\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2021-07-06\n69.788555\n1\n162.270810\n82.273910\n\n\n1\n2021-01-07\n36.289947\n1\n125.240476\n71.164810\n\n\n2\n2022-02-21\n61.501970\n1\n116.044417\n68.405992\n\n\n3\n2020-06-27\n46.299262\n0\n84.440308\n56.924759\n\n\n4\n2021-01-08\n70.127055\n1\n120.693921\n69.800843\n\n\n\n\n\n\n\n\ngenerate_synthetic_data_like(data.head(), n=5)\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2022-02-21\n46.299262\n1\n84.440308\n82.273910\n\n\n1\n2020-06-27\n36.289947\n1\n162.270810\n69.800843\n\n\n2\n2021-01-08\n61.501970\n1\n120.693921\n71.164810\n\n\n3\n2021-01-07\n69.788555\n1\n116.044417\n68.405992\n\n\n4\n2021-07-06\n70.127055\n0\n125.240476\n56.924759"
  },
  {
    "objectID": "basic_plots.html",
    "href": "basic_plots.html",
    "title": "Basic plots",
    "section": "",
    "text": "source\n\ndata_histplot\n\n data_histplot (data:pandas.core.frame.DataFrame, col:str,\n                feature_str:Optional[str]=None, gender_col:str='sex',\n                plot_both_genders:bool=True, ax=None)\n\nPlots a histogram from a DataFrame for a specific column.\nArgs: data (pd.DataFrame): The DataFrame containing the data to plot. col (str): The name of the column to plot. feature_str (Optional[str], optional): The name of the feature to plot. Defaults to None. gender_col (str, optional): The name of the column containing gender information. Defaults to “sex”. plot_both_genders (bool, optional): Whether to plot both genders or just one. Defaults to True. ax ([type], optional): The axis to plot on. Defaults to None.\n\n# Generate synthetic data\ndata = generate_synthetic_data(n=1000)\n\n\ndata_histplot(data=data, col=\"val1\", plot_both_genders=False)\n\n\n\n\n\ndata_histplot(data=data, col=\"val1\")\n\n\n\n\n\nsource\n\n\ndata_ecdfplot\n\n data_ecdfplot (data:pandas.core.frame.DataFrame, col:str,\n                feature_str:Optional[str]=None, gender_col:str='sex',\n                plot_both_genders:bool=True, ax=None)\n\nPlots an empirical cumulative distribution function (ECDF) from a DataFrame for a specific column.\nArgs: data (pd.DataFrame): The DataFrame containing the data to plot. col (str): The name of the column to plot. feature_str (Optional[str], optional): The name of the feature to plot. Defaults to None. gender_col (str, optional): The name of the column containing gender information. Defaults to “sex”. plot_both_genders (bool, optional): Whether to plot both genders or just one. Defaults to True. ax ([type], optional): The axis to plot on. Defaults to None.\n\ndata_ecdfplot(data=data, col=\"val1\", plot_both_genders=False)\n\n\n\n\n\ndata_ecdfplot(data=data, col=\"val1\")\n\n\n\n\n\nsource\n\n\nhist_ecdf_plots\n\n hist_ecdf_plots (data:pandas.core.frame.DataFrame, col:str,\n                  feature_str:Optional[str]=None, gender_col:str='sex',\n                  plot_both_genders:bool=True)\n\nPlots histograms and empirical cumulative distribution functions (ECDFs) from a DataFrame for a specific column.\nArgs: data: The input DataFrame containing the data to plot. col: The column name to plot. feature_str: The title of the plot. If not provided, the column name will be used. gender_col: The column name indicating sex (default is ‘sex’ - female:0; male:1). plot_both_genders (bool, optional): Whether to plot both genders or just one. Defaults to True.\nReturns: None\n\nhist_ecdf_plots(data=data, col=\"val1\")\n\n\n\n\n\nsource\n\n\nplot_stats\n\n plot_stats (data:pandas.core.frame.DataFrame, col:str,\n             ax:matplotlib.axes._axes.Axes, color:str,\n             x_position:float=0.3, label:Optional[str]='All')\n\nAdds a text box to an axis object with summary statistics for a given column in a pandas DataFrame.\nArgs: data (pd.DataFrame): The pandas DataFrame containing the data to calculate statistics for. col (str): The name of the column to calculate statistics for. ax (plt.Axes): The axis object to add the text box to. color (str): The color of the text box. x_position (float, optional): The x position of the text box. Defaults to 0.3. label (Optional[str], optional): The label to display in the text box. Defaults to “All”.\n\nsource\n\n\nplot_hist_stats\n\n plot_hist_stats (data:pandas.core.frame.DataFrame, col:str,\n                  feature_str:Optional[str]=None, gender_col:str='sex',\n                  plot_both_genders:bool=True)\n\nPlots a histogram of a given column in a pandas DataFrame and adds summary statistics to the plot.\nArgs: data (pd.DataFrame): The pandas DataFrame containing the data to plot. col (str): The name of the column to plot. feature_str (Optional[str], optional): A string describing the feature being plotted. Defaults to None. gender_col (str, optional): The name of the column containing gender information. Defaults to “sex”. plot_both_genders (bool, optional): Whether to plot statistics separately for males and females. Defaults to True.\n\n# Generate synthetic data\ndata = generate_synthetic_data(n=1000)\n\n\nplot_hist_stats(data, \"val1\", plot_both_genders=False)\n\n\n\n\n\nplot_hist_stats(data, \"val1\")\n\n\n\n\n\nsource\n\n\nplot_data_collection\n\n plot_data_collection (data:pandas.core.frame.DataFrame,\n                       date_col:str='collection_date',\n                       feature_str:Optional[str]=None,\n                       ax:Optional[matplotlib.axes._axes.Axes]=None)\n\nPlots a histogram of the specified column in a pandas DataFrame and excludes the last point from the plot.\nArgs: data (pd.DataFrame): The pandas DataFrame containing the data to plot. date_col (str, optional): The name of the column containing the dates. Defaults to “collection_date”. feature_str (Optional[str], optional): The name of the feature to plot. If None, the name of the date column will be used. Defaults to None. ax (Optional[plt.Axes], optional): The axis object to plot on. If None, a new figure and axis will be created. Defaults to None.\n\nplot_data_collection(data, date_col=\"date_of_research_stage\", feature_str=\"val1\")\n\n\n\n\n\nsource\n\n\nshow_fundus\n\n show_fundus (fname:str)\n\nDisplay a fundus image from an input file path. Args: fname (str): The file path to the fundus image."
  },
  {
    "objectID": "pheno_loader.html",
    "href": "pheno_loader.html",
    "title": "Pheno loader",
    "section": "",
    "text": "source\n\nPhenoLoader\n\n PhenoLoader (dataset:str, base_path:str='/home/ec2-user/studies/hpp/',\n              cohort:str=None, age_sex_dataset:str='events',\n              skip_dfs:List[str]=[], unique_index:bool=False,\n              valid_dates:bool=False, valid_stage:bool=False,\n              flexible_field_search:bool=False, errors:str='raise',\n              read_parquet_kwargs:Dict[str,Any]={})\n\nClass to load multiple tables from a dataset and allows to easily access their fields.\nArgs:\ndataset (str): The name of the dataset to load.\nbase_path (str, optional): The base path where the data is stored. Defaults to DATASETS_PATH.\ncohort (str, optional): The name of the cohort within the dataset. Defaults to COHORT.\nage_sex_dataset (str, optional): The name of the dataset to use for computing age and sex. Defaults to EVENTS_DATASET.\nskip_dfs (list, optional): A list of tables (or substrings that match to tables) to skip when loading the data. Defaults to [].\nunique_index (bool, optional): Whether to ensure the index of the data is unique. Defaults to False.\nvalid_dates (bool, optional): Whether to ensure that all timestamps in the data are valid dates. Defaults to False.\nvalid_stage (bool, optional): Whether to ensure that all research stages in the data are valid. Defaults to False.\nflexible_field_search (bool, optional): Whether to allow regex field search. Defaults to False.\nerrors (str, optional): Whether to raise an error or issue a warning if missing data is encountered.\n    Possible values are 'raise', 'warn' and 'ignore'. Defaults to 'raise'.\nAttributes:\ndict (pd.DataFrame): The data dictionary for the dataset, containing information about each field.\ndfs (dict): A dictionary of dataframes, one for each table in the dataset.\nfields (list): A list of all fields in the dataset.\ndataset (str): The name of the dataset being used.\ncohort (str): The name of the cohort being used.\nbase_path (str): The base path where the data is stored.\ndataset_path (str): The full path to the dataset being used.\nage_sex_dataset (str): The name of the dataset being used to compute age and sex.\nskip_dfs (list): A list of tables to skip when loading the data.\nunique_index (bool): Whether to ensure the index of the data is unique.\nvalid_dates (bool): Whether to ensure that all timestamps in the data are valid dates.\nvalid_stage (bool): Whether to ensure that all research stages in the data are valid.\nflexible_field_search (bool): Whether to allow regex field search.\nerrors (str): Whether to raise an error or issue a warning if missing data is encountered.\nUse the dataset name to load the dataset. It may contain multiple tables. Age / sex will be added to the data by default. The default base_path is set to work on the research platform.\n\ndl = PhenoLoader('fundus')\ndl\n\nDataLoader for fundus with\n78 fields\n2 tables: ['fundus', 'age_sex']\n\n\nThe DataLoader class contains several usefull attributes\nThe data dictionary of the dataset displays the description of each field.\n\ndl.dict.head(3)\n\n\n\n\n\n\n\n\nfield_string\ndescription_string\nparent_dataframe\nrelative_location\nvalue_type\nunits\nsampling_rate\nitem_type\narray\ncohorts\ndata_type\ndebut\npandas_dtype\n\n\ntabular_field_name\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfundus_image_left\nFundus image (left)\nFundus image (left)\nNaN\n/fundus/fundus.parquet\nText\nNone\nNaN\nBulk\nSingle\n10K\nimage\n2021-02-17\nstring\n\n\nfundus_image_right\nFundus image (right)\nFundus image (right)\nNaN\n/fundus/fundus.parquet\nText\nNone\nNaN\nBulk\nSingle\n10K\nimage\n2021-02-17\nstring\n\n\ncollection_date\nCollection date (YYYY-MM-DD)\nCollection date (YYYY-MM-DD)\nNaN\n/fundus/fundus.parquet\nDate\nTime\nNaN\nData\nSingle\n10K\ntabular\n2021-02-17\ndatetime64[ns]\n\n\n\n\n\n\n\n\ndl.dfs.keys()\n\ndict_keys(['fundus', 'age_sex'])\n\n\n\ndl.dfs['fundus'].head(3)\n\n\n\n\n\n\n\n\n\n\n\nfundus_image_left\nfundus_image_right\ncollection_date\nartery_average_width_left\nartery_average_width_right\nartery_distance_tortuosity_left\nartery_distance_tortuosity_right\nartery_fractal_dimension_left\nartery_fractal_dimension_right\nartery_squared_curvature_tortuosity_left\n...\nvein_fractal_dimension_left\nvein_fractal_dimension_right\nvein_squared_curvature_tortuosity_left\nvein_squared_curvature_tortuosity_right\nvein_tortuosity_density_left\nvein_tortuosity_density_right\nvein_vessel_density_left\nvein_vessel_density_right\nvessel_density_left\nvessel_density_right\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n2022-11-16\n18430.284751\n19038.547771\n3.668175\n3.271147\n1.355673\n1.343602\n40.648267\n...\n1.410553\n1.403108\n14.208195\n6.098432\n0.700187\n0.698546\n0.046645\n0.045864\n0.080377\n0.078671\n\n\n1\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n2022-06-30\n17315.398780\n19099.489575\n2.095461\n1.634782\n1.368933\n1.363413\n24.253169\n...\n1.387527\n1.332864\n8.999069\n8.702682\n0.740806\n0.708911\n0.037896\n0.046853\n0.074197\n0.064578\n\n\n2\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n2021-10-05\n15375.866993\n19855.576862\n2.776472\n2.747015\n1.360404\n1.362699\n9.742353\n...\n1.411881\n1.408791\n13.119227\n9.936669\n0.627281\n0.675100\n0.053022\n0.048063\n0.079515\n0.082102\n\n\n\n\n3 rows × 76 columns\n\n\n\nAll availbale fields (columns) in all tables can be listed.\n\ndl.fields[:5]\n\n['artery_average_width_left',\n 'artery_average_width_right',\n 'artery_distance_tortuosity_left',\n 'artery_distance_tortuosity_right',\n 'artery_fractal_dimension_left']\n\n\nAccess any of the fields (e.g., vein_average_width_right, age) or indices (e.g., research_stage) from any of the tables via the data loader API.\n\ndl[['research_stage', 'vein_average_width_right', 'age', 'sex']]\n\n\n\n\n\n\n\n\n\n\n\nresearch_stage\nvein_average_width_right\nage\nsex\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n00_00_visit\n18436.428634\n43.5\n0\n\n\n1\n10k\n00_00_visit\n0\n00_00_visit\n18888.160314\n53.7\n1\n\n\n2\n10k\n00_00_visit\n0\n00_00_visit\n19013.865043\n26.2\n0\n\n\n3\n10k\n00_00_visit\n0\n00_00_visit\n18809.012493\n44.6\n1\n\n\n4\n10k\n00_00_visit\n0\n00_00_visit\n19428.986690\n50.3\n0\n\n\n\n\n\n\n\nAccess time series or bulk data that is stored separately for each sample via the data loader API. In the following example, the data loader retrieves the relative path of each sample’s bulk file from the main table (where it is stored in the field fundus_image_left), converts it to an absolute path, and loads the file. This is repeated for 2 samples and returned as a list. In the case of parquet DataFrames, there is no need to define the load_func and multiple DFs are concatenated by deafult.\n\ndl.load_sample_data('fundus_image_left', [0, 1], load_func=show_fundus)\n\n[None, None]\n\n\n\n\n\n\n\n\nYou can perform flexible field search (with regex support), when initializing the DataLoader as follows:\n\ndl = PhenoLoader('fundus', flexible_field_search=True)\n\nFor example, the following command will search for any field starting with “fractal”.\n\ndl['^fractal']\n\n\n\n\n\n\n\n\n\n\n\nfractal_dimension_left\nfractal_dimension_right\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n1.564989\n1.520885\n\n\n1\n10k\n00_00_visit\n0\n1.542311\n1.534158\n\n\n2\n10k\n00_00_visit\n0\n1.482051\n1.545097\n\n\n3\n10k\n00_00_visit\n0\n1.548773\n1.539352\n\n\n4\n10k\n00_00_visit\n0\n1.554922\n1.557029\n\n\n\n\n\n\n\nYou can summarize a field or set of fields by the following command\n\ndl.describe_field(['fundus_image_right', 'collection_date'])\n\n\n\n\n\n\n\n\nfundus_image_right\ncollection_date\n\n\n\n\nfield_string\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\ndescription_string\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\nparent_dataframe\nNaN\nNaN\n\n\nrelative_location\n/fundus/fundus.parquet\n/fundus/fundus.parquet\n\n\nvalue_type\nText\nDate\n\n\nunits\nNone\nTime\n\n\nsampling_rate\nNaN\nNaN\n\n\nitem_type\nBulk\nData\n\n\narray\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n\n\ndata_type\nimage\ntabular\n\n\ndebut\n2021-02-17\n2021-02-17\n\n\npandas_dtype\nstring\ndatetime64[ns]\n\n\ncount\n5\n5\n\n\nunique\n1\n5\n\n\nmost_frequent\n/path/to/file\n2021-10-05\n\n\nmin\nNaN\nNaN\n\n\nmax\nNaN\nNaN\n\n\nmean\nNaN\nNaN\n\n\nmedian\nNaN\nNaN\n\n\nstd\nNaN\nNaN"
  },
  {
    "objectID": "date_plots.html",
    "href": "date_plots.html",
    "title": "Dates plots",
    "section": "",
    "text": "source\n\ndates_dist_plot\n\n dates_dist_plot (df:pandas.core.frame.DataFrame, col:str,\n                  sampling_period:str='W-MON', ax:Union[ForwardRef('Extens\n                  ionArray'),numpy.ndarray,ForwardRef('Index'),ForwardRef(\n                  'Series'),List,range,NoneType]=None,\n                  date_col:str='collection_date',\n                  ylim:Optional[Tuple[float,float]]=None,\n                  quantiles:Optional[List[Tuple[float,str]]]=None)\n\nCreates a scatter plot of data points and their statistics based on a specified sampling period.\nArgs: df (pd.DataFrame): The input DataFrame containing the data. col (str): The column name in the DataFrame to plot. sampling_period (str, optional): The frequency to resample the data. Defaults to ‘W-MON’. ax (Optional[Axes], optional): A matplotlib axes object to plot on. Defaults to None. date_col (str, optional): The name of the date column in the DataFrame. Defaults to ‘collection_date’. ylim (Optional[Tuple[float, float]], optional): A tuple defining the y-axis limits. Defaults to None. quantiles (Optional[List[Tuple[float, str]]], optional): A list of tuples containing quantiles and their labels. Defaults to [(0.1, “10%”), (0.9, “90%”)].\n\ndata = generate_synthetic_data()\ndata.head()\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2022-12-01\n57.777073\n1\n150.216212\n56.936487\n\n\n1\n2020-07-29\n53.770724\n1\n117.603875\n47.152785\n\n\n2\n2020-09-30\n51.326393\n1\n97.928950\n41.250308\n\n\n3\n2022-05-06\n61.217276\n0\n105.169939\n41.422605\n\n\n4\n2021-06-29\n45.835170\n0\n54.735540\n26.292285\n\n\n\n\n\n\n\n\ndates_dist_plot(data, col=\"val1\", date_col=\"date_of_research_stage\")"
  },
  {
    "objectID": "blandaltman_plots.html",
    "href": "blandaltman_plots.html",
    "title": "Bland-Altman plots",
    "section": "",
    "text": "source\n\nbland_altman_triple_plot\n\n bland_altman_triple_plot (data:pandas.core.frame.DataFrame, m1_col:str,\n                           m2_col:str, feature_str:str='',\n                           scale:str='linear')\n\nGenerates a triple plot consisting of a scatter correlation plot, Bland-Altman plot, and a percentage Bland-Altman plot.\nArgs: data (pd.DataFrame): A pandas DataFrame containing the data. m1_col (str): The name of the first measurement column in the DataFrame. m2_col (str): The name of the second measurement column in the DataFrame. feature_str (str, optional): A string to include in the title of the plots. Defaults to ““. scale (str, optional): The scale of the axes. Defaults to”linear”.\nReturns: None\n\ndata = generate_synthetic_data(n=1000)\n\nbland_altman_triple_plot(data=data, m1_col=\"val1\",m2_col=\"val2\")"
  },
  {
    "objectID": "cohort_selector.html",
    "href": "cohort_selector.html",
    "title": "Cohort selector",
    "section": "",
    "text": "source\n\nCohortSelector\n\n CohortSelector (base_path:str='/home/ec2-user/studies/hpp/',\n                 cohort:str=None, errors:str='raise', **kwargs)\n\nClass for selecting a subset of a cohort’s data based on a query.\nArgs:\nbase_path (str, optional): Base path of the datasets. Defaults to DATASETS_PATH.\ncohort (str, optional): Name of the cohort. Defaults to COHORT.\nerrors (str, optional): Error action. Defaults to ERROR_ACTION.\n**kwargs: Additional keyword arguments.\nAttributes:\ncohort (str): Name of the cohort.\nbase_path (str): Base path of the datasets.\nerrors (str): Error action.\nkwargs: Additional keyword arguments.\nml (MetaLoader): MetaLoader object for loading metadata and data.\n\ncs = CohortSelector(base_path='examples/')\n\n\ncs.select('15 &lt; ahi &lt; 20 & total_sleep_time &gt; 12000')\n\n\n\n\n\n\n\n\n\n\n\nahi\ntotal_sleep_time\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n9\n10k\n02_00_visit\n2\n18.39\n23748.0\n\n\n15\n10k\n00_00_visit\n0\n19.54\n19230.0\n\n\n30\n10k\n00_00_visit\n0\n18.52\n25111.0\n\n\n42\n10k\n00_00_visit\n1\n17.84\n24966.0\n\n\n49\n10k\n02_00_visit\n0\n17.58\n21980.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n902\n10k\n02_00_visit\n2\n19.78\n24162.0\n\n\n914\n10k\n02_00_visit\n2\n17.54\n26479.0\n\n\n936\n10k\n00_00_visit\n1\n17.43\n20865.0\n\n\n941\n10k\n00_00_visit\n0\n17.82\n17606.0\n\n\n965\n10k\n00_00_visit\n2\n15.38\n24390.0\n\n\n\n\n78 rows × 2 columns"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pheno-utils",
    "section": "",
    "text": "pheno-utils is a dynamic Python package developed by Pheno.AI, for handling our medical datasets. It simplifies data loading, enables effective merging, and offers intuitive visualization tools."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "pheno-utils",
    "section": "Install",
    "text": "Install\npip install pheno_utils"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "pheno-utils",
    "section": "How to use",
    "text": "How to use\nIn order to start using pheno-utils please make sure you have the config.json setup according to your filesystem and located in ~/.pheno/ If you are working on TRE - the file will be generated automaticly for you. If you are working with phenos’ s3 bucket - please run the following code:\npython config_setup/create_default_config.py -d s3://datasets_bucket_name\nExamples:\n\ndata = generate_synthetic_data(n=1000)\nhist_ecdf_plots(data=data, col=\"val1\")\n\n\n\n\n\nage_refplots = GenderAgeRefPlot(data, \"val1\")\nage_refplots.plot()"
  },
  {
    "objectID": "index.html#setting-up-pheno-utils",
    "href": "index.html#setting-up-pheno-utils",
    "title": "pheno-utils",
    "section": "Setting Up pheno-utils",
    "text": "Setting Up pheno-utils\nTo use pheno-utils, you must have a config.json file. This file should be set up according to your filesystem and placed in the ~/.pheno/ directory.\n\nIf You’re Working on TRE\nFor those working in the Trusted Research Environment (TRE), you don’t need to worry about the config.json file. It will be automatically generated for you!\n\n\nIf You’re Working with Phenos’ S3 Bucket\nIf you’re working with Phenos’ S3 bucket, you’ll need to manually create the config.json file. You can do this by running the following Python script:\npython config_setup/create_default_config.py -d s3://datasets_bucket_name\n\n\nIf you are working on local file system\nIf you are working on local file system, you’ll need to manually create the config.json file and locating it under ~/.pheno/ directory. Please use the config_setup/example_config.json as a template for your config.json file."
  },
  {
    "objectID": "age_reference_plots.html",
    "href": "age_reference_plots.html",
    "title": "Age reference plots",
    "section": "",
    "text": "source\n\nget_gam_expectiles\n\n get_gam_expectiles (X:numpy.ndarray, y:numpy.ndarray,\n                     expectiles:List[float]=[0.03, 0.1, 0.5, 0.9, 0.97])\n\nFit Expectile Generalized Additive Models (GAMs) for given expectiles.\nArgs: X (ndarray): Feature data for the model. y (ndarray): Target variable for the model. expectiles (List[float]): List of expectiles to fit. Default is [0.03, 0.1, 0.5, 0.9, 0.97].\nReturns: Tuple[ndarray, Dict[str, ndarray]]: A tuple containing a grid of X values for prediction and a dictionary with expectiles as keys and their corresponding model predictions as values.\n\nsource\n\n\nAgeRefPlot\n\n AgeRefPlot (data:pandas.core.frame.DataFrame, val_col:str,\n             age_col:str='age_at_research_stage', sex_col:str='sex',\n             sex:Optional[int]=None, val_color:Optional[str]=None,\n             ax_main:Optional[matplotlib.axes._axes.Axes]=None,\n             ax_agehist:Optional[matplotlib.axes._axes.Axes]=None,\n             ax_valhist:Optional[matplotlib.axes._axes.Axes]=None,\n             age_bins:Optional[numpy.ndarray]=None,\n             val_bins:Optional[numpy.ndarray]=None, linear_fit:bool=True,\n             expectiles:Optional[List]=[0.03, 0.1, 0.5, 0.9, 0.97],\n             top_disp_perc:float=99, bottom_disp_perc:float=1,\n             robust:bool=True, scale:float=1.0,\n             transform:Optional[Callable]=None, make_fig:bool=True)\n\nInitializes the AgeRefPlot class.\nArgs: data (pd.DataFrame): A pandas DataFrame containing the data. val_col (str): The name of the value column in the DataFrame. age_col (str): The name of the age column in the DataFrame. sex_col (str): The name of the sex column in the DataFrame. sex (Optional[int], optional): The sex to filter the data by. 0 for females and 1 for males. Defaults to None. val_color (Optional[str], optional): The color to use for the value plot. Defaults to None. ax_main (Optional[plt.Axes], optional): The main axis for the plot. Defaults to None. ax_agehist (Optional[plt.Axes], optional): The axis for the age histogram. Defaults to None. ax_valhist (Optional[plt.Axes], optional): The axis for the value histogram. Defaults to None. age_bins (Optional[np.ndarray], optional): The age bins for the histograms. Defaults to None. val_bins (Optional[np.ndarray], optional): The value bins for the histograms. Defaults to None. linear_fit (bool, optional): Whether to perform a linear fit on the data. Defaults to True. expectiles (Optional[List], optional): Whether to calculate and shpe gam expectiles or not. Defaults to [0.03, 0.1, 0.5, 0.9, 0.97]. top_disp_perc (float, optional): The top percentile to use for display. Defaults to 99. bottom_disp_perc (float, optional): The bottom percentile to use for display. Defaults to 1. robust (bool, optional): Whether to use a robust regression method (HuberRegressor) instead of ordinary least squares for linear_fit. Defaults to True. scale (float, optional): The scaling factor for the value column. Defaults to 1. transform (Optional[Callable], optional): The transformation function to apply to the value column. Defaults make_fig (bool, optional): Whether to create a new figure if axes are not provided. Defaults to True.\n\ndata = generate_synthetic_data(n=1000)\n\n\nrefplot = AgeRefPlot(data, \"val1\")\nrefplot.plot()\n\n\n\n\n\nsource\n\n\nGenderAgeRefPlot\n\n GenderAgeRefPlot (data:pandas.core.frame.DataFrame, val_col:str,\n                   age_col:str='age_at_research_stage', sex_col:str='sex',\n                   age_bins:Optional[numpy.ndarray]=None,\n                   val_bins:Optional[numpy.ndarray]=None,\n                   linear_fit:bool=True, expectiles:Optional[List]=[0.03,\n                   0.1, 0.5, 0.9, 0.97], top_disp_perc:float=99,\n                   bottom_disp_perc:float=1, robust:bool=True,\n                   scale:float=1.0, transform:Optional[Callable]=None)\n\nInitializes the GenderAgeRefPlot class.\nArgs: data (pd.DataFrame): The input data containing age, value, and gender columns. val_col (str): The name of the value column in the data. age_col (str): The name of the age column in the DataFrame. sex_col (str): The name of the sex column in the DataFrame. age_bins (np.ndarray, optional): An array of age bin edges. val_bins (np.ndarray, optional): An array of value bin edges. linear_fit (bool, optional): Whether to fit a linear regression line. Defaults to True. expectiles (Optional[List], optional): Whether to calculate and shpe gam expectiles or not. Defaults to [0.03, 0.1, 0.5, 0.9, 0.97]. top_disp_perc (float, optional): The top percentile for data display. Defaults to 99. bottom_disp_perc (float, optional): The bottom percentile for data display. Defaults to 1. robust (bool, optional): Whether to use a robust linear regression. Defaults to True. scale (float, optional): The scaling factor for the data. Defaults to 1. transform (Callable, optional): An optional function to apply to the data. Defaults to None.\n\ngender_refplots = GenderAgeRefPlot(data, \"val1\")\ngender_refplots.plot()"
  },
  {
    "objectID": "cgm_plots.html",
    "href": "cgm_plots.html",
    "title": "CGM plots",
    "section": "",
    "text": "source\n\nCGMPlot\n\n CGMPlot (cgm_df:pandas.core.frame.DataFrame,\n          diet_df:Optional[pandas.core.frame.DataFrame]=None,\n          cgm_date_col:str='collection_timestamp', gluc_col:str='glucose',\n          diet_date_col:str='collection_timestamp',\n          diet_text_col:str='shortname_eng',\n          ax:Optional[matplotlib.axes._axes.Axes]=None, smooth:bool=False,\n          sleep_tuples:Optional[List[Tuple[pandas._libs.tslibs.timestamps.\n          Timestamp,pandas._libs.tslibs.timestamps.Timestamp]]]=None)\n\nInitialize a CGMPlot object.\nArgs: cgm_df (pd.DataFrame): DataFrame containing the glucose measurements. diet_df (Optional[pd.DataFrame], optional): DataFrame containing the diet data. Defaults to None. cgm_date_col (str, optional): Name of the date column in cgm_df. Defaults to “Date”. gluc_col (str, optional): Name of the glucose column in cgm_df. Defaults to “glucose”. diet_date_col (str, optional): Name of the date column in diet_df. Defaults to “Date”. diet_text_col (str, optional): Name of the text column in diet_df. Defaults to “shortname_eng”. ax (Optional[plt.Axes], optional): Matplotlib Axes object to plot on. Defaults to None. smooth (bool, optional): Apply smoothing to the glucose curve. Defaults to False. sleep_tuples (Optional[List[Tuple[pd.Timestamp, pd.Timestamp]]], optional): List of sleep start and end times. Defaults to None.\n\ncgm_df= pd.read_parquet(\"./examples/cgm/cgm.parquet\")\ncgm_df.head()\n\n\n\n\n\n\n\n\n\n\nglucose\n\n\nparticipant_id\ncollection_timestamp\nconnection_id\n\n\n\n\n\n0\n2020-05-25 10:48:00+03:00\n1000001\n111.6\n\n\n2020-05-25 11:03:00+03:00\n1000001\n79.2\n\n\n2020-05-25 11:18:00+03:00\n1000001\n84.6\n\n\n2020-05-25 11:33:00+03:00\n1000001\n106.2\n\n\n2020-05-25 11:48:00+03:00\n1000001\n102.6\n\n\n\n\n\n\n\n\ndiet_df = pd.read_parquet(\"./examples/diet_logging/diet.parquet\")\ndiet_df.head()\n\n\n\n\n\n\n\n\n\ncollection_timestamp\nfood_id\nweight\nshortname_eng\n\n\nparticipant_id\ncohort\n\n\n\n\n\n\n\n\n0\n10k\n2020-05-25 08:15:00+03:00\n1007294\n40.0\nCoffee\n\n\n10k\n2020-05-25 08:15:00+03:00\n1007417\n87.0\nYellow Cheese\n\n\n10k\n2020-05-25 08:15:00+03:00\n1008624\n6.0\nAlmonds\n\n\n10k\n2020-05-25 08:15:00+03:00\n1011642\n12.0\nBrazil nuts\n\n\n10k\n2020-05-25 10:05:00+03:00\n1007118\n100.0\nHummus\n\n\n\n\n\n\n\n\nstart_date = pd.to_datetime('2020-05-25', utc=True).tz_convert('Asia/Jerusalem')\nend_date = pd.to_datetime('2020-05-27',utc=True).tz_convert('Asia/Jerusalem')\n\n\nsample_days = cgm_df[(cgm_df.index.get_level_values('collection_timestamp') &gt;= start_date) \\\n                     & (cgm_df.index.get_level_values('collection_timestamp') &lt;= end_date)]\n\n\ncgmplt = CGMPlot(cgm_df=sample_days.reset_index(),\n                 cgm_date_col=\"collection_timestamp\",\n                 gluc_col=\"glucose\",\n                 diet_df=diet_df.iloc[9:],\n                 diet_date_col=\"collection_timestamp\",\n                 smooth=True)\ncgmplt.plot()\n\n\n\n\n\n\nAGP\n\nsource\n\nAGP\n\n AGP (cgm_df:pandas.core.frame.DataFrame,\n      cgm_date_col:str='collection_timestamp', gluc_col:str='glucose',\n      ax:Optional[matplotlib.axes._axes.Axes]=None)\n\nInitialize an AGP object.\nArgs: cgm_df (pd.DataFrame): DataFrame containing the glucose measurements. cgm_date_col (str, optional): Name of the date column in cgm_df. Defaults to “collection_timestamp”. gluc_col (str, optional): Name of the glucose column in cgm_df. Defaults to “glucose”. ax (Optional[plt.Axes], optional): Matplotlib Axes object to plot on. Defaults to None.\n\nagp = AGP(cgm_df=cgm_df.reset_index(), cgm_date_col=\"collection_timestamp\", gluc_col=\"glucose\")\nagp.plot()"
  },
  {
    "objectID": "meta_loader.html",
    "href": "meta_loader.html",
    "title": "Metadata loader",
    "section": "",
    "text": "source\n\nMetaLoader\n\n MetaLoader (base_path:str='/home/ec2-user/studies/hpp/', cohort:str=None,\n             flexible_field_search:bool=False, errors:str='raise',\n             **kwargs)\n\nClass to load multiple dictionaries and allows to easily access the relevant fields.\nArgs:\nbase_path (str, optional): The base path where the data is stored. Defaults to DATASETS_PATH.\ncohort (str, optional): The name of the cohort within the dataset. Defaults to COHORT.\nflexible_field_search (bool, optional): Whether to allow regex field search. Defaults to False.\nerrors (str, optional): Whether to raise an error or issue a warning if missing data is encountered.\n    Possible values are 'raise', 'warn' and 'ignore'. Defaults to 'raise'.\n**kwargs: Additional keyword arguments to pass to a DataLoader class.\nAttributes:\ndicts (pd.DataFrame): A dictionary of data dictionaries (dataframes) of all availbale datasets in the base_path.\nfields (list): A list of all fields.\ncohort (str): The name of the cohort being used.\nbase_path (str): The base path where the data is stored.\nflexible_field_search (bool): Whether to allow regex field search.\nerrors (str): Whether to raise an error or issue a warning if missing data is encountered.\nkwargs (dict): Additional keyword arguments to pass to a DataLoader class.\nThe MetaLoader can be used to query all availbale fields throughout all datasets. In the following example, 3 datasets are available.\n\nml = MetaLoader()\nml\n\nMetaLoader for: examples/*\nwith 81 fields\n4 datasets:\n['cgm'\n 'diet_logging'\n 'fundus'\n 'sleep']\n\n\nThe object contains only the data dictionaries (metadata) of these datasets, where the columns correspond to columns in the data tables of the dataset (e.g., fundus).\n\nml.dicts['fundus']\n\n\n\n\n\n\n\ntabular_field_name\nfundus_image_left\nfundus_image_right\ncollection_date\n\n\n\n\ndataset\nfundus\nfundus\nfundus\n\n\nfield_string\nFundus image (left)\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\ndescription_string\nFundus image (left)\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\nparent_dataframe\nNaN\nNaN\nNaN\n\n\nrelative_location\n/fundus/fundus.parquet\n/fundus/fundus.parquet\n/fundus/fundus.parquet\n\n\nvalue_type\nText\nText\nDate\n\n\nunits\nNone\nNone\nTime\n\n\nsampling_rate\nNaN\nNaN\nNaN\n\n\nitem_type\nBulk\nBulk\nData\n\n\narray\nSingle\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n10K\n\n\ndata_type\nimage\nimage\ntabular\n\n\ndebut\n2021-02-17\n2021-02-17\n2021-02-17\n\n\npandas_dtype\nstring\nstring\ndatetime64[ns]\n\n\n\n\n\n\n\nYou can query fields from multiple datasets directly:\n\nml[['glucose', 'fundus_image_left']]\n\n\n\n\n\n\n\ntabular_field_name\ncgm/glucose\nfundus/fundus_image_left\n\n\n\n\ndataset\ncgm\nfundus\n\n\nfield_string\nGlucose\nFundus image (left)\n\n\ndescription_string\ncgm temporal glucose values\nFundus image (left)\n\n\nparent_dataframe\nNaN\nNaN\n\n\nrelative_location\n/cgm/cgm.parquet\n/fundus/fundus.parquet\n\n\nvalue_type\nSeries data, continous\nText\n\n\nunits\nmg/dl\nNone\n\n\nsampling_rate\n15min\nNaN\n\n\nitem_type\nData\nBulk\n\n\narray\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n\n\ndata_type\ntime series\nimage\n\n\ndebut\n2018-12-27\n2021-02-17\n\n\npandas_dtype\nfloat\nstring\n\n\n\n\n\n\n\nYou can then use the MetaLoader to load the actual data of fields from multiple datasets. Here we load glucose from the CGM dataset, and fundus_image_left from the fundus dataset.\n\nml.load(['glucose' ,'fundus_image_left']).head()\n\n\n\n\n\n\n\n\n\n\n\n\n\nglucose\nfundus_image_left\n\n\nparticipant_id\ncollection_timestamp\nconnection_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n0\n2020-05-25 10:48:00+03:00\n1000001\n10k\n00_00_visit\n0\n111.6\n/path/to/file\n\n\n2020-05-25 11:03:00+03:00\n1000001\n10k\n00_00_visit\n0\n79.2\n/path/to/file\n\n\n2020-05-25 11:18:00+03:00\n1000001\n10k\n00_00_visit\n0\n84.6\n/path/to/file\n\n\n2020-05-25 11:33:00+03:00\n1000001\n10k\n00_00_visit\n0\n106.2\n/path/to/file\n\n\n2020-05-25 11:48:00+03:00\n1000001\n10k\n00_00_visit\n0\n102.6\n/path/to/file\n\n\n\n\n\n\n\nYou may use more flexible search queries using regex and various properties of the fields. Both the get() method and load() method support the same syntax.\n\nExample: get all bulk data fields.\n\n\nml.get('bulk', flexible=True, prop='item_type')\n\n\n\n\n\n\n\ntabular_field_name\ncgm/cgm_filename\nfundus/fundus_image_left\nfundus/fundus_image_right\n\n\n\n\ndataset\ncgm\nfundus\nfundus\n\n\nfield_string\nCGM timeseries\nFundus image (left)\nFundus image (right)\n\n\ndescription_string\nName of the file containing the participants' ...\nFundus image (left)\nFundus image (right)\n\n\nparent_dataframe\nNaN\nNaN\nNaN\n\n\nrelative_location\n/cgm/cgm.parquet\n/fundus/fundus.parquet\n/fundus/fundus.parquet\n\n\nvalue_type\nText\nText\nText\n\n\nunits\nNaN\nNone\nNone\n\n\nsampling_rate\nNaN\nNaN\nNaN\n\n\nitem_type\nBulk\nBulk\nBulk\n\n\narray\nSingle\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n10K\n\n\ndata_type\ntext\nimage\nimage\n\n\ndebut\n2018-12-27\n2021-02-17\n2021-02-17\n\n\npandas_dtype\nstring\nstring\nstring\n\n\n\n\n\n\n\n\nExample: get all fields that include “mg” in their units\n\n\nml.get('mg', flexible=True, prop='units')\n\n\n\n\n\n\n\ntabular_field_name\ncgm/1st qu_\ncgm/3rd qu_\ncgm/auc\ncgm/ea1c\ncgm/glucose\ncgm/gmi\ncgm/iqr\ncgm/mad\ncgm/mag\ncgm/mage\n...\ncgm/modd\ncgm/range\ncgm/sd\ncgm/sdb\ncgm/sdbdm\ncgm/sddm\ncgm/sdhhmm\ncgm/sdw\ncgm/sdwsh\ndiet_logging/sodium_mg\n\n\n\n\ndataset\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\n...\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ndiet_logging\n\n\nfield_string\n1st quantile\n3rd quantile\nAUC\neA1C\nGlucose\nGMI\nIQR\nMAD\nMAG\nMAGE\n...\nMODD\nRange\nSD\nSDb\nSDbdm\nSDdm\nSDhhmm\nSDw\nSDwsh\nSodium intake per food logged\n\n\ndescription_string\nFirst quantile of all glucose values.\nThird quantile of all glucose values.\nHourly average AUC. This measure integrates, t...\nA linear transformation of the mean glucose va...\ncgm temporal glucose values\nA linear transformation of the mean glucose va...\nInterquartile range (IQR), calculated as the d...\nMedian Absolute Deviation (MAD). This is a mea...\nMean Absolute Glucose (MAG). This is a measure...\nMean Amplitude of Glycemic Excursions (MAGE), ...\n...\nMean difference between glucose values obtaine...\nDifference between the maximum and minimum glu...\nStandard deviation of all glucose values.\nSD between days, within time points. Mean valu...\nSD between days, within time points, corrected...\nHorizontal SD. SD of the mean glucose values, ...\nSD between time points. Standard deviation of ...\nVertical SD within days. Average value of the ...\nSD within series. Taking hour-long intervals t...\nSodium intake per food logged\n\n\nparent_dataframe\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nrelative_location\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n...\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\n/cgm/cgm.parquet\ndiet_logging/diet_logging.parquet\n\n\nvalue_type\nContinuous\nContinuous\nContinuous\nContinuous\nSeries data, continous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\n...\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\n\n\nunits\nmg/dl\nmg/dl\nmg/dl*h\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\n...\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg\n\n\nsampling_rate\nNaN\nNaN\nNaN\nNaN\n15min\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nitem_type\nData\nData\nData\nData\nData\nData\nData\nData\nData\nData\n...\nData\nData\nData\nData\nData\nData\nData\nData\nData\nData\n\n\narray\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\n...\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n...\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n\n\ndata_type\ntabular\ntabular\ntabular\ntabular\ntime series\ntabular\ntabular\ntabular\ntabular\ntabular\n...\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\nTime Series\n\n\ndebut\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n...\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2019-09-01\n\n\npandas_dtype\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\n...\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\n\n\n\n\n14 rows × 24 columns"
  },
  {
    "objectID": "sleep_plots.html",
    "href": "sleep_plots.html",
    "title": "Sleep plots",
    "section": "",
    "text": "source\n\nget_legend_colors\n\n get_legend_colors (cmap='muted')\n\n\nsource\n\n\nformat_xticks\n\n format_xticks (ax, format='%m/%d %H:%M')\n\nformat datestrings on x axis\n\nsource\n\n\nplot_channels\n\n plot_channels (channels:pandas.core.frame.DataFrame,\n                array_index:Optional[int]=None,\n                y_filter:Optional[Iterable[str]]=None,\n                ax:matplotlib.axes._axes.Axes=None,\n                discrete_events:Optional[Iterable[str]]=['sleep_stage',\n                'body_position'], time_col='collection_timestamp',\n                height=1.5, resample='1s', cmap='muted',\n                rename_channels={'actigraph': 'Actigraph',\n                'body_position': 'Body Position', 'heart_rate': 'Heart\n                Rate', 'heart_rate_raw': 'Heart Rate Raw', 'pat_infra':\n                'PAT Infra', 'pat_amplitude': 'PAT Amplitude', 'pat_lpf':\n                'PAT LPF', 'respiratory_movement': 'Respiratory Mov.',\n                'spo2': 'SpO2', 'snore_db': 'Snore dB', 'pat_view': 'PAT\n                View', 'sleep_stage': 'Sleep Stage'}, **kwargs)\n\nplot channels data for a given participant and array_index\n\nsource\n\n\nplot_events\n\n plot_events (events:pandas.core.frame.DataFrame,\n              array_index:Optional[int]=None,\n              x_start:str='collection_timestamp', x_end:str='event_end',\n              y:str='event', color:str='channel', cmap:str='muted',\n              set_xlim:bool=True, xlim:Iterable[float]=None,\n              figsize:Iterable[float]=[10, 4],\n              y_include:Optional[Iterable[str]]=None,\n              y_exclude:Optional[Iterable[str]]=None,\n              ax:matplotlib.axes._axes.Axes=None,\n              add_events:Optional[pandas.core.frame.DataFrame]=None,\n              rename_channels:dict={'PAT Amplitude': 'PAT', 'PulseRate':\n              'Heart Rate'}, rename_events:dict={})\n\nplot an events timeline for a given participant and array_index\n\nsource\n\n\nplot_sleep\n\n plot_sleep (events:pandas.core.frame.DataFrame,\n             channels:pandas.core.frame.DataFrame,\n             array_index:Optional[int]=None,\n             trim_to_events:Optional[bool]=True,\n             add_events:Optional[pandas.core.frame.DataFrame]=None,\n             event_filter:Optional[Iterable[str]]=None,\n             channel_filter:Optional[Iterable[str]]=['actigraph',\n             'pat_infra', 'body_position', 'snore_db', 'heart_rate',\n             'spo2'], event_height:float=2, channel_height:float=0.45,\n             width:float=10, aspect:float=0.2, style:str='whitegrid',\n             xlim:Iterable[float]=None, **kwargs)\n\nPlot sleep events and channels data.\nArgs:\nevents (pd.DataFrame): A pandas dataframe containing sleep events data.\nchannels (pd.DataFrame): A pandas dataframe containing raw channels data.\narray_index (int, optional): The index of the array. Defaults to None.\ntrim_to_events (bool, optional): Whether to trim the plot to the start and end of the events. Defaults to True.\nadd_events (pd.DataFrame, optional): Additional events data to include in the plot. Defaults to None.\nevent_filter (Iterable[str], optional): A list of events to include in the plot. Defaults to None.\nchannel_filter (Iterable[str], optional): A list of channels to include in the plot. Defaults to DEFAULT_CHANNELS.\nevent_height (float, optional): The height of the event plot in inches. Defaults to 2.\nchannel_height (float, optional): The height of each channel plot in inches. Defaults to 0.45.\nwidth (float, optional): The width of the plot in inches. Defaults to 10.\naspect (float, optional): The aspect ratio of the plot. Defaults to 0.2.\nstyle (str, optional): The seaborn style to use. Defaults to 'whitegrid'.\nxlim (List[float], optional): The x-axis limits of the plot. Defaults to None.\n**kwargs: Additional arguments to be passed to plot_channels().\nReturns:\nNone"
  },
  {
    "objectID": "basic_analysis.html",
    "href": "basic_analysis.html",
    "title": "Basic analysis",
    "section": "",
    "text": "source\n\ncustom_describe\n\n custom_describe (df:pandas.core.frame.DataFrame)\n\nGenerates a custom summary statistics dataframe for mixed data types.\nArgs: df: The input pandas DataFrame\nReturns: A pandas DataFrame containing the summary statistics\n\ndata = generate_synthetic_data(n=100)\n\ncustom_describe(data[[\"date_of_research_stage\", \"sex\", \"val2\"]])\n\n\n\n\n\n\n\n\ndate_of_research_stage\nsex\nval2\n\n\n\n\ncount\n100\n100.0\n100.0\n\n\nunique\n99\n2.0\n100.0\n\n\nmost_frequent\nNaN\n0.0\n-3.137486\n\n\nmin\n2020-01-04 00:00:00\n0.0\n-3.137486\n\n\nmax\n2023-06-25 00:00:00\n1.0\n41.432775\n\n\nmean\nNaN\n0.46\n19.091836\n\n\nmedian\nNaN\n0.0\n19.601733\n\n\nstd\nNaN\n0.500908\n10.401328\n\n\n\n\n\n\n\n\nsource\n\n\nassign_nearest_research_stage\n\n assign_nearest_research_stage (dataset:pandas.core.frame.DataFrame,\n                                population:pandas.core.frame.DataFrame,\n                                max_days:int=60,\n                                stages:List[str]=['visit'],\n                                agg:Optional[str]='first')\n\nAssign the nearest research stage to each record in a dataset.\nArgs: dataset (pd.DataFrame): The dataset containing records to be assigned research stages. population (pd.DataFrame): The population data with participant_id, cohort, research_stage, and research_stage_date. max_days (int, optional): The maximum number of days allowed between the collection date and research stage date. Defaults to 60. stages (List[str], optional): The list of types of research stages to consider. Defaults to [‘visit’]. agg (Union[str, None], optional): The aggregation function to be used when (optionally) aggregating multiple rows from the same research stage. The rows are already sorted by distance from the date of the research stage. Can be ‘first’ (closest), ‘last’ (farthest), ‘mean’, ‘min’, ‘max’, or None. Defaults to ‘first’.\nReturns: pd.DataFrame: The dataset with the nearest research stage assigned to each record."
  }
]