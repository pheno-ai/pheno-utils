{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Class for loading datasets on the research platform\n",
    "output-file: pheno_loader.html\n",
    "title: Pheno loader\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pheno_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from glob import glob\n",
    "import traceback\n",
    "\n",
    "import os\n",
    "import re\n",
    "from typing import List, Any, Dict, Union\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from pheno_utils.config import (\n",
    "    DATASETS_PATH,\n",
    "    COHORT, \n",
    "    EVENTS_DATASET, \n",
    "    ERROR_ACTION, \n",
    "    BULK_DATA_PATH\n",
    "    )\n",
    "from pheno_utils.basic_analysis import custom_describe\n",
    "from pheno_utils.basic_plots import show_fundus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class PhenoLoader:\n",
    "    \"\"\"\n",
    "    Class to load multiple tables from a dataset and allows to easily access\n",
    "    their fields.\n",
    "\n",
    "    Args:\n",
    "    \n",
    "        dataset (str): The name of the dataset to load.\n",
    "        base_path (str, optional): The base path where the data is stored. Defaults to DATASETS_PATH.\n",
    "        cohort (str, optional): The name of the cohort within the dataset. Defaults to COHORT.\n",
    "        age_sex_dataset (str, optional): The name of the dataset to use for computing age and sex. Defaults to EVENTS_DATASET.\n",
    "        skip_dfs (list, optional): A list of tables (or substrings that match to tables) to skip when loading the data. Defaults to [].\n",
    "        unique_index (bool, optional): Whether to ensure the index of the data is unique. Defaults to False.\n",
    "        valid_dates (bool, optional): Whether to ensure that all timestamps in the data are valid dates. Defaults to False.\n",
    "        valid_stage (bool, optional): Whether to ensure that all research stages in the data are valid. Defaults to False.\n",
    "        flexible_field_search (bool, optional): Whether to allow regex field search. Defaults to False.\n",
    "        errors (str, optional): Whether to raise an error or issue a warning if missing data is encountered.\n",
    "            Possible values are 'raise', 'warn' and 'ignore'. Defaults to 'raise'.\n",
    "\n",
    "    Attributes:\n",
    "    \n",
    "        dict (pd.DataFrame): The data dictionary for the dataset, containing information about each field.\n",
    "        dfs (dict): A dictionary of dataframes, one for each table in the dataset.\n",
    "        fields (list): A list of all fields in the dataset.\n",
    "        dataset (str): The name of the dataset being used.\n",
    "        cohort (str): The name of the cohort being used.\n",
    "        base_path (str): The base path where the data is stored.\n",
    "        dataset_path (str): The full path to the dataset being used.\n",
    "        age_sex_dataset (str): The name of the dataset being used to compute age and sex.\n",
    "        skip_dfs (list): A list of tables to skip when loading the data.\n",
    "        unique_index (bool): Whether to ensure the index of the data is unique.\n",
    "        valid_dates (bool): Whether to ensure that all timestamps in the data are valid dates.\n",
    "        valid_stage (bool): Whether to ensure that all research stages in the data are valid.\n",
    "        flexible_field_search (bool): Whether to allow regex field search.\n",
    "        errors (str): Whether to raise an error or issue a warning if missing data is encountered.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: str,\n",
    "        base_path: str = DATASETS_PATH,\n",
    "        cohort: str = COHORT,\n",
    "        age_sex_dataset: str = EVENTS_DATASET,\n",
    "        skip_dfs: List[str] = [],\n",
    "        unique_index: bool = False,\n",
    "        valid_dates: bool = False,\n",
    "        valid_stage: bool = False,\n",
    "        flexible_field_search: bool = False,\n",
    "        errors: str = ERROR_ACTION,\n",
    "        read_parquet_kwargs: Dict[str, Any] = {}\n",
    "    ) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.cohort = cohort\n",
    "        self.base_path = base_path\n",
    "        self.dataset_path = self.__get_dataset_path__(self.dataset)\n",
    "        if self.dataset not in [age_sex_dataset, 'population']:\n",
    "            self.age_sex_dataset = age_sex_dataset\n",
    "        else:\n",
    "            self.age_sex_dataset = None\n",
    "        self.skip_dfs = skip_dfs\n",
    "        self.unique_index = unique_index\n",
    "        self.valid_dates = valid_dates\n",
    "        self.valid_stage = valid_stage\n",
    "        self.flexible_field_search = flexible_field_search\n",
    "        self.errors = errors\n",
    "        self.read_parquet_kwargs = read_parquet_kwargs\n",
    "\n",
    "        self.__load_dictionary__()\n",
    "        self.__load_dataframes__()\n",
    "        if self.age_sex_dataset is not None:\n",
    "            self.__load_age_sex__()\n",
    "\n",
    "    def load_sample_data(\n",
    "        self,\n",
    "        field_name: str,\n",
    "        participant_id: Union[int, List[int]],\n",
    "        research_stage: Union[None, str, List[str]] = None,\n",
    "        array_index: Union[None, int, List[int]] = None,\n",
    "        load_func: callable = pd.read_parquet,\n",
    "        concat: bool = True,\n",
    "        pivot=None, **kwargs\n",
    "    ) -> Union[pd.DataFrame, None]:\n",
    "        \"\"\"\n",
    "        Load time series or bulk data for sample(s).\n",
    "\n",
    "        Args:\n",
    "            field_name (str): The name of the field to load.\n",
    "            participant_id (str or list): The participant ID or IDs to load data for.\n",
    "            research_stage (str or list, optional): The research stage or stages to load data for.\n",
    "            array_index (int or list, optional): The array index or indices to load data for.\n",
    "            load_func (callable, optional): The function to use to load the data. Defaults to pd.read_parquet\n",
    "            concat (bool, optional): Whether to concatenate the data into a single DataFrame. Automatically ignored if data is not a DataFrame. Defaults to True.\n",
    "            pivot (str, optional): The name of the field to pivot the data on (if DataFrame). Defaults to None.\n",
    "        \"\"\"\n",
    "        query_str = 'participant_id in @participant_id'\n",
    "        if not isinstance(participant_id, list):\n",
    "            participant_id = [participant_id]\n",
    "        if research_stage is not None:\n",
    "            if not isinstance(research_stage, list):\n",
    "                research_stage = [research_stage]\n",
    "            query_str += ' and research_stage in @research_stage'\n",
    "        if array_index is not None:\n",
    "            if not isinstance(array_index, list):\n",
    "                array_index = [array_index]\n",
    "            query_str += ' and array_index in @array_index'\n",
    "\n",
    "        sample = self[[field_name] + ['participant_id']].query(query_str)\n",
    "        col = sample.columns[0]  # can be different from field_name is a parent_dataframe is implied\n",
    "        sample = sample.astype({col: str})  \n",
    "        missing_participants = np.setdiff1d(participant_id, sample['participant_id'].unique())\n",
    "        sample = sample.loc[:, col]\n",
    "        \n",
    "\n",
    "        if len(missing_participants):\n",
    "            if self.errors == 'raise':\n",
    "                raise ValueError(f'Missing samples: {missing_participants}')\n",
    "            elif self.errors == 'warn':\n",
    "                warnings.warn(f'Missing samples: {missing_participants}')\n",
    "            if len(sample) == 0:\n",
    "                return None\n",
    "\n",
    "        # Load data\n",
    "        data = []\n",
    "        for p in sample.unique():\n",
    "            try:\n",
    "                data.append(load_func(p, **kwargs))\n",
    "                if isinstance(data[-1], pd.DataFrame):\n",
    "                    data[-1].sort_index(inplace=True)\n",
    "            except Exception as e:\n",
    "                if self.errors == 'raise':\n",
    "                    raise e\n",
    "                elif self.errors == 'warn':\n",
    "                    warnings.warn(f'Error loading {p}: {e}')\n",
    "\n",
    "        # Format the final result\n",
    "        if concat and isinstance(data[0], pd.DataFrame):\n",
    "            data = pd.concat(data, axis=0)\n",
    "        if pivot is not None and isinstance(data, pd.DataFrame):\n",
    "            if pivot in data.index.names:\n",
    "                data = data.reset_index(pivot)\n",
    "            data = data.pivot(columns=pivot)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Return string representation of object\n",
    "\n",
    "        Returns:\n",
    "            str: String representation of object\n",
    "        \"\"\"\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Return string representation of object\n",
    "\n",
    "        Returns:\n",
    "            str: String representation of object\n",
    "        \"\"\"\n",
    "        return f'DataLoader for {self.dataset} with' +\\\n",
    "            f'\\n{len(self.fields)} fields\\n{len(self.dfs)} tables: {list(self.dfs.keys())}'\n",
    "\n",
    "    def __getitem__(self, fields: Union[str,List[str]]):\n",
    "        \"\"\"\n",
    "        Return data for the specified fields from all tables\n",
    "\n",
    "        Args:\n",
    "            fields (Union[str, List[str]]): Fields to return\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Data for the specified fields from all tables\n",
    "        \"\"\"\n",
    "        return self.get(fields)\n",
    "\n",
    "    def get(self, fields: Union[str,List[str]], flexible: bool=None):\n",
    "        \"\"\"\n",
    "        Return data for the specified fields from all tables\n",
    "\n",
    "        Args:\n",
    "            fields (List[str]): Fields to return\n",
    "            flexible (bool, optional): Whether to use fuzzy matching to find fields. Defaults to None, which uses the DataLoader's flexible_field_search attribute.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Data for the specified fields from all tables\n",
    "        \"\"\"\n",
    "        if flexible is None:\n",
    "            flexible = self.flexible_field_search\n",
    "        if isinstance(fields, str):\n",
    "            fields = [fields]\n",
    "\n",
    "        # check whether any field points to a parent_dataframe\n",
    "        # has_parent = self.dict.loc[self.dict.index.isin(fields), 'parent_dataframe'].dropna()\n",
    "        seen_fields = set()\n",
    "        parent_dict = self.dict.loc[self.dict.index.isin(fields), 'parent_dataframe'].dropna().to_dict()\n",
    "        fields = [parent_dict.get(field, field) for field in fields]\n",
    "        fields = [field for field in fields if field not in seen_fields and not seen_fields.add(field)]\n",
    "        # fields += has_parent.unique().tolist()\n",
    "        flexi_fields = list()\n",
    "\n",
    "        data = pd.DataFrame()\n",
    "        for df in self.dfs.values():\n",
    "            if flexible:\n",
    "                # use fuzzy matching including regex to find fields\n",
    "                fields_in_col = np.unique([col for f in fields for col in df.columns if re.search(f, col)])\n",
    "                flexi_fields += fields_in_col.tolist()\n",
    "            else:\n",
    "                fields_in_col = df.columns.intersection(fields).difference(data.columns)\n",
    "            if len(fields_in_col):\n",
    "                data = self.__concat__(data, df[fields_in_col])\n",
    "\n",
    "            fields_in_index = np.setdiff1d(np.intersect1d(df.index.names, fields), data.columns)\n",
    "            for field in fields_in_index:\n",
    "                data = self.__concat__(\n",
    "                    data,\n",
    "                    pd.DataFrame(df.index.get_level_values(field), index=df.index))\n",
    "\n",
    "        if len(data):\n",
    "            data = data.loc[:, ~data.columns.duplicated()]\n",
    "\n",
    "        not_found = np.setdiff1d(fields, data.columns)\n",
    "        if len(not_found) and not flexible:\n",
    "            if self.errors == 'raise':\n",
    "                raise KeyError(f'Fields not found: {not_found}')\n",
    "            elif self.errors == 'warn':\n",
    "                warnings.warn(f'Fields not found: {not_found}')\n",
    "        \n",
    "        data = self.replace_bulk_data_path(data, fields)\n",
    "        \n",
    "        cols_order = [field for field in fields if field in data.columns]\n",
    "        cols_order += [field for field in flexi_fields if (field in data.columns and field not in fields)]\n",
    "\n",
    "        return data[cols_order]\n",
    "    \n",
    "\n",
    "    def replace_bulk_data_path(self, data, fields):\n",
    "        bulk_fields = self.dict.loc[self.dict.index.isin(fields)].query('item_type == \"Bulk\"')\n",
    "        cols = [col for col in bulk_fields.index.to_list() if col in data.columns] \n",
    "        dataset_bulk_data_path = {k:v.format(dataset=self.dataset) for k, v in BULK_DATA_PATH.items()}\n",
    "        category_cols = self.dict.loc[self.dict.index.isin(fields)].query('pandas_dtype == \"category\"').index\n",
    "    \n",
    "        for col in category_cols: \n",
    "            data[col] = data[col].astype(str)\n",
    "\n",
    "        data[cols] = data[cols].fillna('nan').replace(dataset_bulk_data_path, regex=True)\n",
    "        for col in category_cols: \n",
    "            data[col] = data[col].astype('category')\n",
    "            \n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "    def __concat__(self, df1, df2):\n",
    "        if df1.empty:\n",
    "            return df2\n",
    "        if df2.empty:\n",
    "            return df1\n",
    "        return df1.join(df2, how='outer')\n",
    "\n",
    "    def __load_age_sex__(self) -> None:\n",
    "        \"\"\"\n",
    "        Add sex and compute age from birth date.\n",
    "        \"\"\"\n",
    "        age_path = os.path.join(self.__get_dataset_path__(self.age_sex_dataset), 'events.parquet')\n",
    "        align_df = self.dfs[list(self.dfs)[0]]\n",
    "\n",
    "        if ('research_stage' in align_df.columns) or ('research_stage' in align_df.index.names):\n",
    "            try:\n",
    "                age_df = pd.read_parquet(age_path)\n",
    "                self.dfs['age_sex'] = align_df.join(\n",
    "                    age_df[['age_at_research_stage', 'sex']].droplevel('array_index'))\\\n",
    "                    .rename(columns={'age_at_research_stage': 'age'})[['age', 'sex']]\n",
    "\n",
    "            except Exception as e:\n",
    "                if self.errors == 'raise':\n",
    "                    raise(e)\n",
    "                elif self.errors == 'warn':\n",
    "                    warnings.warn(f'Error joining research_stage: {e}')\n",
    "                self.dfs['age_sex'] = pd.DataFrame(index=align_df.index).assign(age=np.nan, sex=np.nan)\n",
    "\n",
    "        else:\n",
    "            # init an empty df\n",
    "            self.dfs['age_sex'] = pd.DataFrame(index=align_df.index).assign(age=np.nan, sex=np.nan)\n",
    "\n",
    "        self.fields += ['age', 'sex']\n",
    "        ind = self.dfs['age_sex'].isnull().any(axis=1)\n",
    "        if not ind.any():  # no missing values\n",
    "            return\n",
    "\n",
    "        # fill in missing values by computing age from birth date\n",
    "        try:\n",
    "            date_cols = np.array(['collection_date', 'collection_timestamp', 'sequencing_date'])\n",
    "            date = date_cols[np.isin(date_cols, align_df.columns)][0]  # prefer first match\n",
    "        except Exception as e:\n",
    "            if self.errors == 'raise':\n",
    "                raise(e)\n",
    "            elif self.errors == 'warn':\n",
    "                warnings.warn(f'No date field found')\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            ind &= align_df[date].notnull()\n",
    "        except Exception as e:\n",
    "            if self.errors == 'raise':\n",
    "                raise(e)\n",
    "            if self.errors == 'warn':\n",
    "                warnings.warn(f'Error checking date field: {e}')\n",
    "            return\n",
    "        if not ind.any():\n",
    "            return\n",
    "\n",
    "        age_df = pd.read_parquet(age_path.replace('events', 'population'))\n",
    "\n",
    "        # trying a workaround for a pandas deprecation warning\n",
    "        age_sex = self.dfs['age_sex']\n",
    "        try:\n",
    "            age_df['birth_date'] = pd.to_datetime(\n",
    "                age_df['year_of_birth'].astype(str) + '-' + age_df['month_of_birth'].astype(str))\n",
    "\n",
    "            missing_age_sex = align_df.loc[ind, [date]].join(age_df[['sex', 'birth_date']])\\\n",
    "                .assign(age=lambda x: ((x[date] - x['birth_date']).dt.days / 365.25).round(1))\\\n",
    "                [['age', 'sex']]\n",
    "            age_sex = age_sex.join(missing_age_sex, rsuffix='_miss')\n",
    "\n",
    "        except Exception as e:\n",
    "            if self.errors == 'raise':\n",
    "                print(\"Exception occurred:\\n\", traceback.format_exc())\n",
    "                raise(e)\n",
    "            elif self.errors == 'warn':\n",
    "                warnings.warn(f'Error joining on {date}: {e}')\n",
    "\n",
    "            age_sex = age_sex.join(age_df[['sex']], rsuffix='_miss').assign(age_miss=np.nan)\n",
    "\n",
    "        age_sex['age'] = age_sex['age'].fillna(age_sex['age_miss'])\n",
    "        age_sex['sex'] = age_sex['sex'].fillna(age_sex['sex_miss'])\n",
    "        self.dfs['age_sex'] = age_sex[['age', 'sex']]\n",
    "\n",
    "    def __load_dataframes__(self) -> None:\n",
    "        \"\"\"\n",
    "        Load all tables in the dataset dictionary.\n",
    "        \"\"\"\n",
    "        self.dfs = {}\n",
    "        self.fields = set()\n",
    "        for relative_location in self.dict['relative_location'].dropna().unique():\n",
    "            # parquet_name = relative_location.split(os.sep)[-1]\n",
    "            parquet_name = os.sep.join(relative_location.split(os.sep)[2:])\n",
    "            \n",
    "            if any([pattern in relative_location for pattern in self.skip_dfs]):\n",
    "                print(f'Skipping {relative_location}')\n",
    "                continue\n",
    "            df = self.__load_one_dataframe__(parquet_name)\n",
    "            if df is None:\n",
    "                continue\n",
    "            table_name = parquet_name.split('.')[0].split(os.sep)[-1]\n",
    "            self.dfs[table_name] = df\n",
    "            if not df.index.is_unique:\n",
    "                print('Warning: index is not unique for', parquet_name)\n",
    "            self.fields |= set(self.dfs[table_name].columns.tolist())\n",
    "        self.fields = sorted(list(self.fields))\n",
    "\n",
    "    def __load_one_dataframe__(self, relative_location: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load one dataframe.\n",
    "\n",
    "        Args:\n",
    "            relative_location (str): the location of the dataframe\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: the loaded dataframe\n",
    "        \"\"\"\n",
    "    \n",
    "        df_path = os.path.join(self.dataset_path, relative_location)\n",
    "        \n",
    "        try:\n",
    "            data =  pd.read_parquet(df_path, **self.read_parquet_kwargs)\n",
    "        except Exception as err:\n",
    "            if self.errors == 'raise':\n",
    "                warnings.warn(f'Error loading {df_path}:\\n{err}')\n",
    "                raise err\n",
    "            if self.errors == 'warn':\n",
    "                warnings.warn(f'Error loading {df_path}:\\n{err}')\n",
    "            return None\n",
    "\n",
    "        # set the order of columns according to the dictionary\n",
    "        dict_columns = self.dict.index.intersection(data.columns)\n",
    "        other_columns = data.columns.difference(self.dict.index)\n",
    "        assert (len(dict_columns) + len(other_columns)) == len(data.columns), \"something isn't right\"\n",
    "        data = data[dict_columns.tolist() + other_columns.tolist()]\n",
    "\n",
    "        before = len(data)\n",
    "        if self.unique_index:\n",
    "            data = data.loc[~data.index.duplicated()]\n",
    "        if self.valid_dates:\n",
    "            data = data.loc[data.select_dtypes(include=['datetime64[ns]']).notnull().any(axis=1)]\n",
    "        if self.valid_stage:\n",
    "            data = data.loc[data.index.get_level_values('research_stage').notnull()]\n",
    "        after = len(data)\n",
    "        if before > after:\n",
    "            print(f'Filtered {before - after} rows')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __load_dictionary__(self) -> None:\n",
    "        \"\"\"\n",
    "        Load dataset dictionary.\n",
    "        \"\"\"\n",
    "        self.dict = pd.read_csv(self.__get_dictionary_file_path__(self.dataset))\\\n",
    "            .set_index('tabular_field_name')\n",
    "        self.fields = self.dict.index.tolist()\n",
    "\n",
    "    def __get_file_path__(self, dataset: str, extension: str) -> str:\n",
    "        \"\"\"\n",
    "        Get the file path for a dataset and an extension.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): the name of the dataset\n",
    "            extension (str): the extension of the file\n",
    "\n",
    "        Returns:\n",
    "            str: the path to the file\n",
    "        \"\"\"\n",
    "        path = os.path.join(self.dataset_path, '*.' + extension)\n",
    "        if path.startswith('s3://'):\n",
    "           return path\n",
    "        return glob(path)[0]\n",
    "\n",
    "    def __get_dictionary_file_path__(self, dataset: str) -> str:\n",
    "        \"\"\"\n",
    "        Get the file path for data dictionary.\n",
    "\n",
    "        Args:\n",
    "            dataset (str): the name of the dataset\n",
    "\n",
    "        Returns:\n",
    "            str: the path to the file\n",
    "        \"\"\"\n",
    "        path = os.path.join(self.dataset_path, f'{dataset}_data_dictionary.csv')\n",
    "        if path.startswith('s3://'):\n",
    "           return path\n",
    "        return glob(path)[0]\n",
    "\n",
    "    def __get_dataset_path__(self, dataset):\n",
    "        \"\"\"\n",
    "        Get the dataset path.\n",
    "        \n",
    "        Args:\n",
    "            dataset (str): the name of the dataset\n",
    "\n",
    "        Returns:\n",
    "            str: the path to the dataset\n",
    "        \"\"\"\n",
    "        if self.cohort is not None:\n",
    "            return os.path.join(self.base_path, dataset, self.cohort)\n",
    "        return os.path.join(self.base_path, dataset)\n",
    "\n",
    "    def describe_field(self, fields: Union[str,List[str]], return_summary: bool=False):\n",
    "        \"\"\"\n",
    "        Display a summary dataframe for the specified fields from all tables\n",
    "\n",
    "        Args:\n",
    "            fields (List[str]): Fields to return\n",
    "            return_summary (Bool): whether to return the summary dataframe\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Data for the specified fields from all tables\n",
    "        \"\"\"\n",
    "        if isinstance(fields, str):\n",
    "            fields = [fields]\n",
    "        \n",
    "        summary_df = pd.concat([self.dict.loc[fields,:].T,\n",
    "                                custom_describe(self[fields])])\n",
    "        display(summary_df)\n",
    "        if return_summary:\n",
    "            return summary_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dataset name to load the dataset. It may contain multiple tables. Age / sex will be added to the data by default. The default `base_path` is set to work on the research platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader for fundus with\n",
       "78 fields\n",
       "2 tables: ['fundus', 'age_sex']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = PhenoLoader('fundus')\n",
    "dl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataLoader class contains several usefull attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary of the dataset displays the description of each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_string</th>\n",
       "      <th>description_string</th>\n",
       "      <th>parent_dataframe</th>\n",
       "      <th>relative_location</th>\n",
       "      <th>value_type</th>\n",
       "      <th>units</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>item_type</th>\n",
       "      <th>array</th>\n",
       "      <th>cohorts</th>\n",
       "      <th>data_type</th>\n",
       "      <th>debut</th>\n",
       "      <th>pandas_dtype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabular_field_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fundus_image_left</th>\n",
       "      <td>Fundus image (left)</td>\n",
       "      <td>Fundus image (left)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/fundus/fundus.parquet</td>\n",
       "      <td>Text</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>image</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fundus_image_right</th>\n",
       "      <td>Fundus image (right)</td>\n",
       "      <td>Fundus image (right)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/fundus/fundus.parquet</td>\n",
       "      <td>Text</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>image</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection_date</th>\n",
       "      <td>Collection date (YYYY-MM-DD)</td>\n",
       "      <td>Collection date (YYYY-MM-DD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/fundus/fundus.parquet</td>\n",
       "      <td>Date</td>\n",
       "      <td>Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data</td>\n",
       "      <td>Single</td>\n",
       "      <td>10K</td>\n",
       "      <td>tabular</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    field_string  \\\n",
       "tabular_field_name                                 \n",
       "fundus_image_left            Fundus image (left)   \n",
       "fundus_image_right          Fundus image (right)   \n",
       "collection_date     Collection date (YYYY-MM-DD)   \n",
       "\n",
       "                              description_string  parent_dataframe  \\\n",
       "tabular_field_name                                                   \n",
       "fundus_image_left            Fundus image (left)               NaN   \n",
       "fundus_image_right          Fundus image (right)               NaN   \n",
       "collection_date     Collection date (YYYY-MM-DD)               NaN   \n",
       "\n",
       "                         relative_location value_type units  sampling_rate  \\\n",
       "tabular_field_name                                                           \n",
       "fundus_image_left   /fundus/fundus.parquet      Text   None            NaN   \n",
       "fundus_image_right  /fundus/fundus.parquet      Text   None            NaN   \n",
       "collection_date     /fundus/fundus.parquet       Date  Time            NaN   \n",
       "\n",
       "                   item_type   array cohorts data_type       debut  \\\n",
       "tabular_field_name                                                   \n",
       "fundus_image_left       Bulk  Single     10K     image  2021-02-17   \n",
       "fundus_image_right      Bulk  Single     10K     image  2021-02-17   \n",
       "collection_date         Data  Single     10K   tabular  2021-02-17   \n",
       "\n",
       "                      pandas_dtype  \n",
       "tabular_field_name                  \n",
       "fundus_image_left           string  \n",
       "fundus_image_right          string  \n",
       "collection_date     datetime64[ns]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dict.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fundus', 'age_sex'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fundus_image_left</th>\n",
       "      <th>fundus_image_right</th>\n",
       "      <th>collection_date</th>\n",
       "      <th>artery_average_width_left</th>\n",
       "      <th>artery_average_width_right</th>\n",
       "      <th>artery_distance_tortuosity_left</th>\n",
       "      <th>artery_distance_tortuosity_right</th>\n",
       "      <th>artery_fractal_dimension_left</th>\n",
       "      <th>artery_fractal_dimension_right</th>\n",
       "      <th>artery_squared_curvature_tortuosity_left</th>\n",
       "      <th>...</th>\n",
       "      <th>vein_fractal_dimension_left</th>\n",
       "      <th>vein_fractal_dimension_right</th>\n",
       "      <th>vein_squared_curvature_tortuosity_left</th>\n",
       "      <th>vein_squared_curvature_tortuosity_right</th>\n",
       "      <th>vein_tortuosity_density_left</th>\n",
       "      <th>vein_tortuosity_density_right</th>\n",
       "      <th>vein_vessel_density_left</th>\n",
       "      <th>vein_vessel_density_right</th>\n",
       "      <th>vessel_density_left</th>\n",
       "      <th>vessel_density_right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th>cohort</th>\n",
       "      <th>research_stage</th>\n",
       "      <th>array_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>18430.284751</td>\n",
       "      <td>19038.547771</td>\n",
       "      <td>3.668175</td>\n",
       "      <td>3.271147</td>\n",
       "      <td>1.355673</td>\n",
       "      <td>1.343602</td>\n",
       "      <td>40.648267</td>\n",
       "      <td>...</td>\n",
       "      <td>1.410553</td>\n",
       "      <td>1.403108</td>\n",
       "      <td>14.208195</td>\n",
       "      <td>6.098432</td>\n",
       "      <td>0.700187</td>\n",
       "      <td>0.698546</td>\n",
       "      <td>0.046645</td>\n",
       "      <td>0.045864</td>\n",
       "      <td>0.080377</td>\n",
       "      <td>0.078671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>17315.398780</td>\n",
       "      <td>19099.489575</td>\n",
       "      <td>2.095461</td>\n",
       "      <td>1.634782</td>\n",
       "      <td>1.368933</td>\n",
       "      <td>1.363413</td>\n",
       "      <td>24.253169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.387527</td>\n",
       "      <td>1.332864</td>\n",
       "      <td>8.999069</td>\n",
       "      <td>8.702682</td>\n",
       "      <td>0.740806</td>\n",
       "      <td>0.708911</td>\n",
       "      <td>0.037896</td>\n",
       "      <td>0.046853</td>\n",
       "      <td>0.074197</td>\n",
       "      <td>0.064578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>15375.866993</td>\n",
       "      <td>19855.576862</td>\n",
       "      <td>2.776472</td>\n",
       "      <td>2.747015</td>\n",
       "      <td>1.360404</td>\n",
       "      <td>1.362699</td>\n",
       "      <td>9.742353</td>\n",
       "      <td>...</td>\n",
       "      <td>1.411881</td>\n",
       "      <td>1.408791</td>\n",
       "      <td>13.119227</td>\n",
       "      <td>9.936669</td>\n",
       "      <td>0.627281</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.053022</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>0.079515</td>\n",
       "      <td>0.082102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 fundus_image_left  \\\n",
       "participant_id cohort research_stage array_index                     \n",
       "0              10k    00_00_visit    0               /path/to/file   \n",
       "1              10k    00_00_visit    0               /path/to/file   \n",
       "2              10k    00_00_visit    0               /path/to/file   \n",
       "\n",
       "                                                 fundus_image_right  \\\n",
       "participant_id cohort research_stage array_index                      \n",
       "0              10k    00_00_visit    0                /path/to/file   \n",
       "1              10k    00_00_visit    0                /path/to/file   \n",
       "2              10k    00_00_visit    0                /path/to/file   \n",
       "\n",
       "                                                 collection_date  \\\n",
       "participant_id cohort research_stage array_index                   \n",
       "0              10k    00_00_visit    0                2022-11-16   \n",
       "1              10k    00_00_visit    0                2022-06-30   \n",
       "2              10k    00_00_visit    0                2021-10-05   \n",
       "\n",
       "                                                  artery_average_width_left  \\\n",
       "participant_id cohort research_stage array_index                              \n",
       "0              10k    00_00_visit    0                         18430.284751   \n",
       "1              10k    00_00_visit    0                         17315.398780   \n",
       "2              10k    00_00_visit    0                         15375.866993   \n",
       "\n",
       "                                                  artery_average_width_right  \\\n",
       "participant_id cohort research_stage array_index                               \n",
       "0              10k    00_00_visit    0                          19038.547771   \n",
       "1              10k    00_00_visit    0                          19099.489575   \n",
       "2              10k    00_00_visit    0                          19855.576862   \n",
       "\n",
       "                                                  artery_distance_tortuosity_left  \\\n",
       "participant_id cohort research_stage array_index                                    \n",
       "0              10k    00_00_visit    0                                   3.668175   \n",
       "1              10k    00_00_visit    0                                   2.095461   \n",
       "2              10k    00_00_visit    0                                   2.776472   \n",
       "\n",
       "                                                  artery_distance_tortuosity_right  \\\n",
       "participant_id cohort research_stage array_index                                     \n",
       "0              10k    00_00_visit    0                                    3.271147   \n",
       "1              10k    00_00_visit    0                                    1.634782   \n",
       "2              10k    00_00_visit    0                                    2.747015   \n",
       "\n",
       "                                                  artery_fractal_dimension_left  \\\n",
       "participant_id cohort research_stage array_index                                  \n",
       "0              10k    00_00_visit    0                                 1.355673   \n",
       "1              10k    00_00_visit    0                                 1.368933   \n",
       "2              10k    00_00_visit    0                                 1.360404   \n",
       "\n",
       "                                                  artery_fractal_dimension_right  \\\n",
       "participant_id cohort research_stage array_index                                   \n",
       "0              10k    00_00_visit    0                                  1.343602   \n",
       "1              10k    00_00_visit    0                                  1.363413   \n",
       "2              10k    00_00_visit    0                                  1.362699   \n",
       "\n",
       "                                                  artery_squared_curvature_tortuosity_left  \\\n",
       "participant_id cohort research_stage array_index                                             \n",
       "0              10k    00_00_visit    0                                           40.648267   \n",
       "1              10k    00_00_visit    0                                           24.253169   \n",
       "2              10k    00_00_visit    0                                            9.742353   \n",
       "\n",
       "                                                  ...  \\\n",
       "participant_id cohort research_stage array_index  ...   \n",
       "0              10k    00_00_visit    0            ...   \n",
       "1              10k    00_00_visit    0            ...   \n",
       "2              10k    00_00_visit    0            ...   \n",
       "\n",
       "                                                  vein_fractal_dimension_left  \\\n",
       "participant_id cohort research_stage array_index                                \n",
       "0              10k    00_00_visit    0                               1.410553   \n",
       "1              10k    00_00_visit    0                               1.387527   \n",
       "2              10k    00_00_visit    0                               1.411881   \n",
       "\n",
       "                                                  vein_fractal_dimension_right  \\\n",
       "participant_id cohort research_stage array_index                                 \n",
       "0              10k    00_00_visit    0                                1.403108   \n",
       "1              10k    00_00_visit    0                                1.332864   \n",
       "2              10k    00_00_visit    0                                1.408791   \n",
       "\n",
       "                                                  vein_squared_curvature_tortuosity_left  \\\n",
       "participant_id cohort research_stage array_index                                           \n",
       "0              10k    00_00_visit    0                                         14.208195   \n",
       "1              10k    00_00_visit    0                                          8.999069   \n",
       "2              10k    00_00_visit    0                                         13.119227   \n",
       "\n",
       "                                                  vein_squared_curvature_tortuosity_right  \\\n",
       "participant_id cohort research_stage array_index                                            \n",
       "0              10k    00_00_visit    0                                           6.098432   \n",
       "1              10k    00_00_visit    0                                           8.702682   \n",
       "2              10k    00_00_visit    0                                           9.936669   \n",
       "\n",
       "                                                  vein_tortuosity_density_left  \\\n",
       "participant_id cohort research_stage array_index                                 \n",
       "0              10k    00_00_visit    0                                0.700187   \n",
       "1              10k    00_00_visit    0                                0.740806   \n",
       "2              10k    00_00_visit    0                                0.627281   \n",
       "\n",
       "                                                  vein_tortuosity_density_right  \\\n",
       "participant_id cohort research_stage array_index                                  \n",
       "0              10k    00_00_visit    0                                 0.698546   \n",
       "1              10k    00_00_visit    0                                 0.708911   \n",
       "2              10k    00_00_visit    0                                 0.675100   \n",
       "\n",
       "                                                  vein_vessel_density_left  \\\n",
       "participant_id cohort research_stage array_index                             \n",
       "0              10k    00_00_visit    0                            0.046645   \n",
       "1              10k    00_00_visit    0                            0.037896   \n",
       "2              10k    00_00_visit    0                            0.053022   \n",
       "\n",
       "                                                 vein_vessel_density_right  \\\n",
       "participant_id cohort research_stage array_index                             \n",
       "0              10k    00_00_visit    0                            0.045864   \n",
       "1              10k    00_00_visit    0                            0.046853   \n",
       "2              10k    00_00_visit    0                            0.048063   \n",
       "\n",
       "                                                 vessel_density_left  \\\n",
       "participant_id cohort research_stage array_index                       \n",
       "0              10k    00_00_visit    0                      0.080377   \n",
       "1              10k    00_00_visit    0                      0.074197   \n",
       "2              10k    00_00_visit    0                      0.079515   \n",
       "\n",
       "                                                  vessel_density_right  \n",
       "participant_id cohort research_stage array_index                        \n",
       "0              10k    00_00_visit    0                        0.078671  \n",
       "1              10k    00_00_visit    0                        0.064578  \n",
       "2              10k    00_00_visit    0                        0.082102  \n",
       "\n",
       "[3 rows x 76 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dfs['fundus'].head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All availbale fields (columns) in all tables can be listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artery_average_width_left',\n",
       " 'artery_average_width_right',\n",
       " 'artery_distance_tortuosity_left',\n",
       " 'artery_distance_tortuosity_right',\n",
       " 'artery_fractal_dimension_left']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.fields[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access any of the fields (e.g., `vein_average_width_right`, `age`) or indices (e.g., `research_stage`) from any of the tables via the data loader API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>research_stage</th>\n",
       "      <th>vein_average_width_right</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th>cohort</th>\n",
       "      <th>research_stage</th>\n",
       "      <th>array_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>00_00_visit</td>\n",
       "      <td>18436.428634</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>00_00_visit</td>\n",
       "      <td>18888.160314</td>\n",
       "      <td>53.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>00_00_visit</td>\n",
       "      <td>19013.865043</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>00_00_visit</td>\n",
       "      <td>18809.012493</td>\n",
       "      <td>44.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>00_00_visit</td>\n",
       "      <td>19428.986690</td>\n",
       "      <td>50.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 research_stage  \\\n",
       "participant_id cohort research_stage array_index                  \n",
       "0              10k    00_00_visit    0              00_00_visit   \n",
       "1              10k    00_00_visit    0              00_00_visit   \n",
       "2              10k    00_00_visit    0              00_00_visit   \n",
       "3              10k    00_00_visit    0              00_00_visit   \n",
       "4              10k    00_00_visit    0              00_00_visit   \n",
       "\n",
       "                                                  vein_average_width_right  \\\n",
       "participant_id cohort research_stage array_index                             \n",
       "0              10k    00_00_visit    0                        18436.428634   \n",
       "1              10k    00_00_visit    0                        18888.160314   \n",
       "2              10k    00_00_visit    0                        19013.865043   \n",
       "3              10k    00_00_visit    0                        18809.012493   \n",
       "4              10k    00_00_visit    0                        19428.986690   \n",
       "\n",
       "                                                   age  sex  \n",
       "participant_id cohort research_stage array_index             \n",
       "0              10k    00_00_visit    0            43.5    0  \n",
       "1              10k    00_00_visit    0            53.7    1  \n",
       "2              10k    00_00_visit    0            26.2    0  \n",
       "3              10k    00_00_visit    0            44.6    1  \n",
       "4              10k    00_00_visit    0            50.3    0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl[['research_stage', 'vein_average_width_right', 'age', 'sex']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access time series or bulk data that is stored separately for each sample via the data loader API. In the following example, the data loader retrieves the relative path of each sample's bulk file from the main table (where it is stored in the field `fundus_image_left`), converts it to an absolute path, and loads the file. This is repeated for 2 samples and returned as a list. In the case of parquet DataFrames, there is no need to define the `load_func` and multiple DFs are concatenated by deafult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "dl.dfs['fundus']['fundus_image_left'] = [f'M0/images/fundus_{i}.png' for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl.load_sample_data('fundus_image_left', [0, 1], load_func=show_fundus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform flexible field search (with regex support), when initializing the DataLoader as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = PhenoLoader('fundus', flexible_field_search=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the following command will search for any field starting with \"fractal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fractal_dimension_left</th>\n",
       "      <th>fractal_dimension_right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th>cohort</th>\n",
       "      <th>research_stage</th>\n",
       "      <th>array_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>1.564989</td>\n",
       "      <td>1.520885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>1.542311</td>\n",
       "      <td>1.534158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>1.482051</td>\n",
       "      <td>1.545097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>1.548773</td>\n",
       "      <td>1.539352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>10k</th>\n",
       "      <th>00_00_visit</th>\n",
       "      <th>0</th>\n",
       "      <td>1.554922</td>\n",
       "      <td>1.557029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fractal_dimension_left  \\\n",
       "participant_id cohort research_stage array_index                           \n",
       "0              10k    00_00_visit    0                          1.564989   \n",
       "1              10k    00_00_visit    0                          1.542311   \n",
       "2              10k    00_00_visit    0                          1.482051   \n",
       "3              10k    00_00_visit    0                          1.548773   \n",
       "4              10k    00_00_visit    0                          1.554922   \n",
       "\n",
       "                                                  fractal_dimension_right  \n",
       "participant_id cohort research_stage array_index                           \n",
       "0              10k    00_00_visit    0                           1.520885  \n",
       "1              10k    00_00_visit    0                           1.534158  \n",
       "2              10k    00_00_visit    0                           1.545097  \n",
       "3              10k    00_00_visit    0                           1.539352  \n",
       "4              10k    00_00_visit    0                           1.557029  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl['^fractal']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can summarize a field or set of fields by the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fundus_image_right</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>field_string</th>\n",
       "      <td>Fundus image (right)</td>\n",
       "      <td>Collection date (YYYY-MM-DD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description_string</th>\n",
       "      <td>Fundus image (right)</td>\n",
       "      <td>Collection date (YYYY-MM-DD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_dataframe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_location</th>\n",
       "      <td>/fundus/fundus.parquet</td>\n",
       "      <td>/fundus/fundus.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value_type</th>\n",
       "      <td>Text</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>units</th>\n",
       "      <td>None</td>\n",
       "      <td>Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampling_rate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_type</th>\n",
       "      <td>Bulk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>array</th>\n",
       "      <td>Single</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohorts</th>\n",
       "      <td>10K</td>\n",
       "      <td>10K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <td>image</td>\n",
       "      <td>tabular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debut</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2021-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pandas_dtype</th>\n",
       "      <td>string</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_frequent</th>\n",
       "      <td>/path/to/file</td>\n",
       "      <td>2021-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fundus_image_right               collection_date\n",
       "field_string          Fundus image (right)  Collection date (YYYY-MM-DD)\n",
       "description_string    Fundus image (right)  Collection date (YYYY-MM-DD)\n",
       "parent_dataframe                       NaN                           NaN\n",
       "relative_location   /fundus/fundus.parquet        /fundus/fundus.parquet\n",
       "value_type                           Text                           Date\n",
       "units                                 None                          Time\n",
       "sampling_rate                          NaN                           NaN\n",
       "item_type                             Bulk                          Data\n",
       "array                               Single                        Single\n",
       "cohorts                                10K                           10K\n",
       "data_type                            image                       tabular\n",
       "debut                           2021-02-17                    2021-02-17\n",
       "pandas_dtype                        string                datetime64[ns]\n",
       "count                                    5                             5\n",
       "unique                                   1                             5\n",
       "most_frequent                /path/to/file                    2021-10-05\n",
       "min                                    NaN                           NaN\n",
       "max                                    NaN                           NaN\n",
       "mean                                   NaN                           NaN\n",
       "median                                 NaN                           NaN\n",
       "std                                    NaN                           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl.describe_field(['fundus_image_right', 'collection_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
